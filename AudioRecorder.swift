import AVFoundation
import Combine
import AppKit


extension Notification.Name {
    static let startWaveform = Notification.Name("startWaveform")
    static let stopWaveform = Notification.Name("stopWaveform")
}


class AudioRecorder: NSObject, ObservableObject {
    private var audioRecorder: AVAudioRecorder?
    @Published var audioFileURL: URL?
    @Published var isRecording = false
    @Published var isPaused = false
    @Published var formattedNotes: String? = "Waiting for transcription..."
    @Published var isTranscribing = false
    @Published var isGeneratingNotes = false
    @Published var transcribedNotes: String? = "Transcription in progress..."
    @Published var consoleOutput: String = ""
    @Published var audioPower: Double = 0.0 // üî• Stores real-time audio level
    
    
    


    static let shared = AudioRecorder() // Singleton instance

    override init() {
        super.init()
        requestMicrophoneAccess()
    }
    
    func openStorageDirectory() {
        let downloadsDir = FileManager.default.urls(for: .downloadsDirectory, in: .userDomainMask).first!
        let customDir = downloadsDir.appendingPathComponent("LectureToNotesCache")
        
        // Check if directory exists
        if FileManager.default.fileExists(atPath: customDir.path) {
            NSWorkspace.shared.open(customDir)
            Logger.shared.log("üìÇ Opened storage directory: \(customDir.path)")
        } else {
            Logger.shared.log("‚ö†Ô∏è Directory does not exist yet: \(customDir.path)")
            // Optionally create the directory if it doesn't exist
            do {
                try FileManager.default.createDirectory(at: customDir, withIntermediateDirectories: true, attributes: nil)
                NSWorkspace.shared.open(customDir)
                Logger.shared.log("üìÇ Created and opened storage directory: \(customDir.path)")
            } catch {
                Logger.shared.log("‚ùå Failed to create directory: \(error.localizedDescription)")
            }
        }
    }
    
    
    
    // Allows the user to select an audio file and triggers transcription + notes generation
    func importAudioFile() {
        let openPanel = NSOpenPanel()
        openPanel.title = "Select an Audio File"
        openPanel.allowedContentTypes = [.audio] // Only allow audio files
        openPanel.allowsMultipleSelection = false
        openPanel.canChooseDirectories = false

        openPanel.begin { response in
            if response == .OK, let selectedFileURL = openPanel.url {
                DispatchQueue.main.async {
                    self.audioFileURL = selectedFileURL
                    self.isTranscribing = true
                    Logger.shared.log("üéµ Selected audio file: \(selectedFileURL.lastPathComponent)")
                    
                    // Trigger transcription and notes generation
                    self.transcribeRecording(audioFile: selectedFileURL)
                }
            } else {
                Logger.shared.log("‚ö†Ô∏è File selection canceled or failed.")
            }
        }
    }
    
    private func logToConsole(_ message: String) {
        DispatchQueue.main.async {
            self.consoleOutput = message  // Overwrite with the latest message
            print(self.consoleOutput)     // Also print to Xcode console
        }
    }
    
    func redoTranscription() {
            // Logic to redo the transcription
        }

    func startRecording() {
        Logger.shared.log("üé§ Starting new recording...")

        // Reset state for new session
        DispatchQueue.main.async {
            self.formattedNotes = "Waiting for transcription..."
            self.transcribedNotes = nil
            self.isGeneratingNotes = false
            self.isTranscribing = false
        }

        // Create custom directory in Downloads if it doesn't exist
        let downloadsDir = FileManager.default.urls(for: .downloadsDirectory, in: .userDomainMask).first!
        let customDir = downloadsDir.appendingPathComponent("LectureToNotesCache")
        
        do {
            try FileManager.default.createDirectory(at: customDir, withIntermediateDirectories: true, attributes: nil)
        } catch {
            Logger.shared.log("‚ùå Failed to create directory: \(error.localizedDescription)")
        }
        
        // Create unique filename with timestamp
        let dateFormatter = DateFormatter()
        dateFormatter.dateFormat = "yyyyMMdd_HHmmss"
        let timestamp = dateFormatter.string(from: Date())
        let audioFilename = customDir.appendingPathComponent("lecture_\(timestamp).m4a")
        
        Logger.shared.log("üìÅ Saving recording to: \(audioFilename.path)")
        
        let settings: [String: Any] = [
            AVFormatIDKey: Int(kAudioFormatMPEG4AAC),
            AVSampleRateKey: 44100,
            AVNumberOfChannelsKey: 1,
            AVEncoderAudioQualityKey: AVAudioQuality.high.rawValue
        ]

        do {
            audioRecorder = try AVAudioRecorder(url: audioFilename, settings: settings)
            audioRecorder?.delegate = self
            audioRecorder?.prepareToRecord()
            audioRecorder?.isMeteringEnabled = true // ‚úÖ Enable metering to track volume
            audioRecorder?.record()
            
            // Start monitoring audio levels
            Timer.scheduledTimer(withTimeInterval: 0.1, repeats: true) { timer in
                guard let recorder = self.audioRecorder, recorder.isRecording else {
                    timer.invalidate() // Stop timer if recording stops
                    return
                }
                
                recorder.updateMeters()
                let power = pow(10, recorder.averagePower(forChannel: 0) / 20) // Convert to linear scale

                // Boost amplitude by a factor of 2 (or change this to whatever suits your needs)
                let boostedPower = power * 100.0 // Boost the power level by a factor (e.g., 2.0)
                
                DispatchQueue.main.async {
                    self.audioPower = Double(min(boostedPower, 50.0)) // Ensure power value doesn't exceed 1.0
                }
                
                recorder.updateMeters()
                DispatchQueue.main.async {
                    self.audioPower = Double(power) // ‚úÖ Convert Float to Double
                }
            }

            DispatchQueue.main.async {
                self.audioFileURL = audioFilename
                self.isRecording = true
                self.isPaused = false
                DispatchQueue.main.async{
                    Logger.shared.log("‚úÖ Recording started successfully.")
                }
                
                NotificationCenter.default.post(name: .startWaveform, object: nil)
            }
        } catch {
            Logger.shared.log("‚ùå Failed to start recording: \(error.localizedDescription)")
        }
    }

    func pauseRecording() {
        Logger.shared.log("‚è∏ Attempting to pause recording...")
        guard let recorder = audioRecorder, recorder.isRecording else {
            Logger.shared.log("‚ö†Ô∏è Cannot pause: No active recording.")
            return
        }
        recorder.pause()
        DispatchQueue.main.async {
            self.isPaused = true
            Logger.shared.log("‚úÖ Recording paused.")
        }
    }

    func resumeRecording() {
        Logger.shared.log("‚ñ∂Ô∏è Attempting to resume recording...")
        guard let recorder = audioRecorder, !recorder.isRecording else {
            Logger.shared.log("‚ö†Ô∏è Cannot resume: No paused recording.")
            return
        }
        recorder.record() // ‚úÖ Actually resume recording
        DispatchQueue.main.async {
            self.isPaused = false
            self.isRecording = true
            Logger.shared.log("‚úÖ Recording resumed.")
        }
    }

    func stopRecording() {
        Logger.shared.log("üõë Attempting to stop recording...")
        guard let recorder = audioRecorder else {
            Logger.shared.log("‚ö†Ô∏è Cannot stop: No active recording.")
            return
        }
        recorder.stop()
        
        DispatchQueue.main.async {
            self.isRecording = false
            self.isPaused = false
            self.audioRecorder = nil
            Logger.shared.log("‚úÖ Recording stopped.")
            NotificationCenter.default.post(name: .stopWaveform, object: nil)
            self.audioPower = 0.0 // üî• Reset power level when recording stops


            if let fileURL = self.audioFileURL {
                Logger.shared.log("üìÅ Recorded file available at: \(fileURL.path)")
                if !self.isTranscribing { // Prevent duplicate calls
                    self.isTranscribing = true
                    self.transcribeRecording(audioFile: fileURL)
                }
            } else {
                Logger.shared.log("‚ùå No valid audio file URL after stopping recording.")
            }
        }
    }

    private func requestMicrophoneAccess() {
        Logger.shared.log("üîä Requesting microphone access...")
        AVCaptureDevice.requestAccess(for: .audio) { granted in
            DispatchQueue.main.async {
                if granted {
                    Logger.shared.log("‚úÖ Microphone access granted.")
                } else {
                    Logger.shared.log("‚ùå Microphone access denied.")
                }
            }
        }
    }

    func transcribeRecording(audioFile: URL) {
        Logger.shared.log("üìù Sending file to WhisperAI for transcription: \(audioFile.path)")
        
        guard !self.isGeneratingNotes else {
            Logger.shared.log("‚ö†Ô∏è Notes are already being generated. Skipping duplicate request.")
            return
        }
        
        self.isGeneratingNotes = true

        WhisperAI.shared.transcribeAudio(audioURL: audioFile) { transcription in
            DispatchQueue.main.async {
                if let transcription = transcription {
                    Logger.shared.log("‚úÖ Transcription completed. Preparing to generate study notes...")
                    self.transcribedNotes = transcription
                    
                    // Get the parent directory of the audio file
                    let audioDirectory = audioFile.deletingLastPathComponent()
                    let baseFilename = audioFile.deletingPathExtension().lastPathComponent
                    
                    // Save transcript to same directory as audio
                    let transcriptFile = audioDirectory.appendingPathComponent("\(baseFilename)_transcript.txt")
                    do {
                        try transcription.write(to: transcriptFile, atomically: true, encoding: .utf8)
                        Logger.shared.log("üìÑ Transcript saved to: \(transcriptFile.path)")
                        print("Transcript saved at: \(transcriptFile.path)")
                    } catch {
                        Logger.shared.log("‚ùå Failed to save transcript: \(error.localizedDescription)")
                    }

                    OpenAIClient.shared.generateStudyNotes(from: audioFile) { notes, tokens, cost in
                        DispatchQueue.main.async {
                            Logger.shared.log("‚úÖ Notes successfully generated.")
                            self.formattedNotes = notes
                            self.isGeneratingNotes = false
                            self.isTranscribing = false
                            
                            // Save notes to same directory (no optional binding needed)
                            let notesFile = audioDirectory.appendingPathComponent("\(baseFilename)_notes.txt")
                            do {
                                try notes.write(to: notesFile, atomically: true, encoding: .utf8)
                                Logger.shared.log("üìù Notes saved to: \(notesFile.path)")
                                print("Notes saved at: \(notesFile.path)")
                            } catch {
                                Logger.shared.log("‚ùå Failed to save notes: \(error.localizedDescription)")
                            }
                        }
                    }
                } else {
                    Logger.shared.log("‚ùå Transcription failed.")
                    self.transcribedNotes = "Transcription failed."
                    self.formattedNotes = "Transcription failed."
                    self.isGeneratingNotes = false
                    self.isTranscribing = false
                }
            }
        }
    }
    
    
}



extension AudioRecorder: AVAudioRecorderDelegate {
    func audioRecorderDidFinishRecording(_ recorder: AVAudioRecorder, successfully flag: Bool) {
        if flag {
            Logger.shared.log("‚úÖ Recording saved at: \(recorder.url.path)")
            transcribeRecording(audioFile: recorder.url)
        } else {
            Logger.shared.log("‚ùå Recording failed.")
            DispatchQueue.main.async {
                self.isRecording = false
                self.isPaused = false
            }
        }
    }
}
